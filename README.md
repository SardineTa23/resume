# 職務経歴書

## 基本情報
- Name: 岩下 拳勝
- Twitter: [@iwashi623](https://twitter.com/iwashi623)
- PR TIMES開発者プログ [公開エントリ](https://developers.prtimes.jp/author/kenshoiwashita/)
- [Wantedly](https://www.wantedly.com/id/kensho_iwashita)
- [Speaker Deck](https://speakerdeck.com/iwashi623)
- [Qiita](https://qiita.com/iwashi623)
- [Zenn](https://zenn.dev/iwashi623)
- [note](https://note.com/iwashi623)

## スキル
### 言語
PHP | Ruby | Go

### フレームワーク、Middleware、Hardware
Laravel | Ruby on Rails | MySQL | PostgreSQL | nginx

### AWS
EC2 | ECS | Fargate | ECR | Lambda | ALB | VPC | VPC Peering | IAM | CloudFront | Route53 | RDS(MySQL | PostgreSQL) | Aurora | S3 | ElastiCache(Redis) | SQS | SNS | Chatbot | Parameter Store | Glue | EventBridge | CloudWatch | DirectConnect

### その他
GitHub | GitHub Actions | Terraform | NewRelic | Fastly | ecspresso | lambroll

### ライセンス
 - AWS Certified Solutions Architect – Associate（2021/08）
 - AWS Certified Developer - Associate（2022/03）
 - AWS Certified SysOps Administrator - Associate（2022/08）
 - AWS Certified Solutions Architect - Professional（2022/10）

## 言語
- 日本語
  - ネイティブ
- 英語
  - 読み書きレベル

## バリューを発揮しやすい業務
 - PHPやRubyを使用したサーバーサイドのWebアプリケーション開発
 - CI/CDパイプラインの構築や改善
 - クラウドサービスを使ったアーキテクチャ設計
 - クラウドサービスのインフラ構築･環境のコード化

## 価値観
なにか一つのことに集中して数年単位で何かを成し遂げるよりも､多くの失敗を重ねながらたくさんのチャレンジをすることに価値を感じる性格です｡
[16Personalities性格診断テスト](https://www.16personalities.com/ja)の結果は[ENTP](https://www.16personalities.com/ja/entp%E5%9E%8B%E3%81%AE%E6%80%A7%E6%A0%BC)です｡

一方で､型にはまった作業や踏襲されてきた歴史などを無心で重んじるのが苦手で､そういった状況に陥るとバリューの低下やメンタルの不健康を感じます｡

## 興味・関心
ソフトウェア開発､とりわけWeb業界は知識の幅が広く､執筆時点で(2023/1 現在)はすべての分野を一通り触ったとは全く言えない状況です｡そのため前述したような性格でも毎日楽しく学習ができています｡エンジニアの業務は十分知的好奇心を刺激されて楽しく働くことができているため､しばらくはエンジニアとしてキャリアを築いていきたいです｡

エンジニアの中では､これまでのキャリアで主にサーバーサイドやクラウドサービスを利用したインフラ構築を担当してきました｡ただ､そこにこだわりがあるわけではなく､むしろ幅を更に広げていきたいと考えています｡GoやKotlinなどの静的型付け言語やTypeScrip+FWを使ったフロントエンド開発､ネイティブアプリケーション開発にも興味があります｡

## 職務経歴
### 2021/04 - 現在 : 株式会社PR TIMES
#### 職務内容
 - Webアプリケーションバックエンド開発･クラウドインフラ構築運用｡
 - 2021/07より､[PRTIMES STORY](https://prtimes.jp/story)開発リーダー｡
 おもにアプリケーションのリアーキテクチャや開発環境改善､CDNの導入などを担当した｡
 - PR TIMES AWS移行プロジェクトのメンバー｡インフラのコード化や関連サービスのDBの接続先変更(VPC Peering､DirectConnectの設定)を担当｡
#### 職務の中で学んだことや得られた知識・スキルなど
技術的な詳細は下記する｡ここではその他の経験を述べます｡

チームメンバーは4〜6人の少数チームだが､開発リーダーとして工数管理や実装優先度の決定をしていました｡手を動かしてコードを書く以外の主な業務は､ビジネスサイドの要望に対して､開発をすすめるにあたっての要件の切り出しやDesing Docの作成です｡

担当しているプロダクトがユーザーの少ない新規サービスで､さらに開発がなかなか進んでいない状況でした｡そこで最小工数でできるだけ早くリリースして､社内の信頼を勝ち取ることを目標にしていました｡

また､積極的な情報発信を会社が運営しているブログ上で行いました｡インターネットに知識を還元することはもちろん､自分自身や会社の開発組織の価値向上につながると肌で感じることができました｡

## 開発実績
### Webアプリケーションのリアーキテクチャと運用(〜現在)
#### 公開エントリ
 - [PR TIMES STORYを別リポジトリに移植した話](https://developers.prtimes.jp/2022/10/05/transportation_story_program/)
 - [公開予定記事あり]()

#### 概要
担当サービスが変に分割されており､また分割された片方がもう一方と全く違うFWを採用していることや､開発組織のエンジニア以外にその事実を知っていることが少ないことなどが原因となり､開発速度が出しづらい環境を抱えていた｡また､社内のサービスと一つだけ別ドメインを使用していることでCDNの設定やCORSの設定を独自で行う必要があり､少ないエンジニアリソースが無駄になっている面もあった｡

そのような状況を打開するために､分割されたサービスの統合や､ドメイン変更などを行い､以後の変更や機能開発で余計な工数がかからないようにした｡

アプリケーション移植プロジェクト
 - 分割されたサービスの統合では､独自FWで管理されているコードを､Laravelに移植した｡基本は同じPHPなので動作したが､deprecatedになっている関数や無意味なリクエストをしているところもあったため､慎重にTestを書きながら1ページずつWebアプリケーションを移植する手法をとった｡
 - 1ページずつ移植するために､ALBのホストベース･パスベースのルーティング機能を使用した｡ページごとにリスナールールを書き足していくことにより実現できた｡また､既存ECSにリクエストが流れてくるため､NewRelicのエージェントを用いたECSの監視も追加した｡

ドメイン変更プロジェクト
 - 基本はLaravelのルーティングファイルを変更して､移植先ドメインで使用するパスへリクエストが来たら､対応するControllerを呼び出すようにした｡これだけであたらしいエンドポイントへも今まで通りの形でレスポンスを返せるようになる｡
 - ただし､エンドポイントの名前が変更されることもあり､動作はするがリポジトリのアーキテクチャ上あるべき場所に無いコードが大量に発生した｡それらは､リファクタリングデーで一気に移植することで地道に正常状態へ戻していった｡
 - すでに古いドメインをブックマークしているユーザーがいることも考慮に入れて､古いエンドポイントは消さず､内部処理で新ドメインのエンドポイントへリダイレクトさせる設計になっている｡

Desing Docを実装前に丁寧に書くことで､スコープ内･外のことやリリースの方法(1ページずつリリースするなど)を予めきめて走り切ることができた｡

#### 使用技術
PHP | Laravel | ECS | ALB | NewRelic | Terraform 

### ECSのマルチステージ環境開発(2022/03頃)
#### 公開エントリ
 - [ECSでマルチステージング環境を実現した設計と実装](https://developers.prtimes.jp/2022/04/22/ecs-multistg-deploy/)
 - [CloudFrontのディストリビューションを分割して、マルチステージング環境をさらに便利にした話](https://developers.prtimes.jp/2022/11/09/divide_cloudfront_distribution_for_multi_staging/)

#### 概要
担当していたサービスの"検証環境が一つしかない"という状況だった｡この状況では､チームが大きくなった際に並行でプロジェクトを動かしていく際にQA確認などですべての開発が詰まることは明白であった｡実際､開発チームが少人数の状況でも､QAやエンジニアの検証作業が開発の流れのボトルネックになっていた｡

そのため､誰でも自由にそれぞれがデプロイできる環境の作成をして､チームの開発速度向上に貢献した｡また､社内の別ECSサービスにも取り入れられている仕組みとなり､別チームが導入する際は実装のレビュアーやアドバイスなども行った｡
 - 設計は既存環境をECSとほぼ同じ構成で､検証環境のサブドメインとして各人の環境がデプロイできるようにした｡
   - 仮に検証環境のドメインが`example.com`だとすると､`hoge.example.com`のドメインで各人が自由な環境をデプロイすることができる｡
 - デプロイはGitHub Actionsを使用して､[ecspresso](https://github.com/kayac/ecspresso)コマンドを使うことによって実現している｡
 - DBまわりは他のステージング環境と共用している｡これはステージング毎にDBを分けると「起動･停止に時間がかかること」や「コストのかかる割に､それに見合うリターンが現状見込めないこと」に起因している｡
   - 実現しようと思ったら､ecspressoのタスク定義ファイルを､GitHub Actionsのinputの値をもとにデプロイするECSのDBHostの値を書き換える､もしくはアプリケーションにDBの参照先を変更する管理画面に入れるなどして対応予定｡
 - ECS以外のAWSリソースはTerrafromを使って作成した｡
   - ECSやALB､Security Groupの設定などは初めて一人で行ったが､公式ドキュメントやAWS認定資格の際に勉強した知識を活かして実装を進めた｡
   - 「ALBには2つのドメインの証明書を関連付けられる」や「CloudFrontではホストベースのルーティングは不可」などの知見を実装しながら学んでいった｡

結果として､複数のプロジェクトの並行実施やリファクタリングデーの定期実行､デザイナーへの確認などがスムーズに行えるようになった｡
#### 使用技術
ECS | ECR | ALB | ACM | ALB | CloudFront | GitHub Actions | ecspresso | Terraform

### BigQueryをつかった社内のデータ分析基盤整理(2021/11-2022/01頃)
#### 公開エントリ
 - [AuroraからBigQueryへデータ転送する際のシステム構成
](https://developers.prtimes.jp/2022/03/02/aurora_to_bigquery/)
#### 概要
 - データをBigQueryにエクスポートするにあたって転送すべきではないデータも含まれていた｡
   - サービスの性質上､公開前情報なども扱うため安易にDBのデータをそのままBigQueryに転送はできない｡
   - 秘匿情報などマスキングや転送データから削除するべきデータは､[AWS Glue](https://aws.amazon.com/jp/glue/)を使用したETL処理を行った｡Glueを使って変換処理を終えたファイルをS3に書き出し､そのファイルをBigQueryに転送することで要件を満たした｡
 - Aurora MySQLのsnapshotの機能を使用して､リードレプリカなどを使わずにデータをGlueで読み込む
   - Glueの処理用にAuroraMySQLのリードレプリカを新たにたてる方法もあったが､その方法ではDBサーバーの料金が無駄になると考えた｡
     - そのため､AuroraのSnapshotをつかって､Glueでデータを読み込む手法を選定した｡
   - スナップショットのS3への転送にはLambdaでデプロイしたGoアプリケーションを使用した｡[ブログ](https://developers.prtimes.jp/2022/03/02/aurora_to_bigquery)に実際がコード載っている｡
     - データの取得→変換→転送の処理を完全に自動化するために､EvendbridgeやBigQueryの定期実行Jobを使用した｡
 - ただBigQueryでデータを閲覧できるようにしただけでは､ビジネスサイドの人がデータを見るのには障壁がある(クエリを書く必要があるため)｡そのため､Google DataStudioとBigQueryの定期実行Jobを使用して､毎日更新されるダッシュボードを作成した｡これにより､ビジネスサイドの方でもかんたんに毎日の配信件数などを把握できる様になった｡

実際にビジネスサイドの人にどういったデータがほしいか(Ex: 毎日の新規投稿数､週ごとの新規投稿企業数など)をヒアリングして､ダッシュボードに日々アップデートをかけていった｡
#### 使用技術
Python | Go | Lambda | lambroll | S3 | KMS | Aurora MySQL | Glue | EventBridge | CloudWatch | BigQuery

## 課外活動
### 登壇など
 - PHPカンファレンス2022 スポンサーLT登壇
   - [登壇資料](https://speakerdeck.com/iwashi623/aa-wo-ranoecs-1)
   - [映像](https://www.youtube.com/watch?v=wFjGeFafagU)

### 社外プロジェクト(OSSなど)
特になし

## 個人開発
### gjobctl
 - リポジトリ: https://github.com/iwashi623/gjobctl
 - 機能: [README](https://github.com/iwashi623/gjobctl/blob/main/README.md)
 - 概要: Glue Jobを作成･管理をするときにほしいAPIをラップしたツール｡

#### 作成背景
1. スクリプトをリポジトリで管理したいこと
2. Jobをコンソールから作成するのが手間だったこと

があげられる｡

1は自身がGlue Jobのスクリプトをデバッグのために編集を加えたり･戻する際に感じた課題感である｡リポジトリ管理がされておらず､現状の実装が何を意図して実装されたのかわからなくなることが多かった｡

これはGitHubのリポジトリでスクリプトを管理することで解決できる｡GitHubでスクリプトを管理するようになると､当然GitHub Actionsを使用して自動デプロイもできたら嬉しいという要望も出てくる｡これだけであればGitHub Actionsで`aws s3`コマンドを叩けば実現できる｡

ただ､別件で2も常々思っていた｡ソースデータのテーブル･カラムが追加されるたびに､AWSのコンソールに行って同じような設定のJobをポチポチ作るのも､一回一回はそれほど手間でもないが積み重なると辛い｡

そこで､スクリプトのデプロイとJobの作成･更新ができるツールを作成した｡
 - Jobの管理はTerraform
 - スクリプトはリポジトリ管理して`aws s3`コマンド

という運用も悪くないかと思ったが､スクリプトファイルとJobの設定ファイルを近く(同じリポジトリにおける)というのもメリットかと思い製作した｡言語選定については､勉強したかったという理由とバイナリ配布が容易である点からGoを選択した｡
